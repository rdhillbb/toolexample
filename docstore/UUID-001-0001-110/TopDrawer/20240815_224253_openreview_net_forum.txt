URL: https://openreview.net/forum?id=5Xc1ecxO1h
Content length: 2961
Content:
Tree of Thoughts: Deliberate Problem Solving with Large Language Models | OpenReviewToggle navigationOpenReview.netLoginOpen Peer Review. Open Publishing. Open Access. Open Discussion. Open Recommendations. Open Directory. Open API. Open Source.×Tree of Thoughts: Deliberate Problem Solving with Large Language ModelsShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik R Narasimhan Published: 21 Sept 2023, Last Modified: 02 Nov 2023NeurIPS 2023 oralEveryoneRevisionsBibTeXKeywords: large language model, general problem solving, heuristic search, reasoning, planning, decision makingTL;DR: We combine LLM's capabilities of generating and evaluating diverse “thoughts” with search algorithms for robust problem solving.Abstract: Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models’ problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/princeton-nlp/tree-of-thought-llm.Submission Number: 7806LoadingAbout OpenReviewHosting a VenueAll VenuesContactFeedbackSponsorsJoin the TeamFrequently Asked QuestionsTerms of UsePrivacy PolicyAbout OpenReviewHosting a VenueAll VenuesSponsorsJoin the TeamFrequently Asked QuestionsContactFeedbackTerms of UsePrivacy PolicyOpenReview is a long-term project to advance science through improved peer review, with legal nonprofit status through Code for Science & Society. We gratefully acknowledge the support of the OpenReview Sponsors. © 2024 OpenReview×Send FeedbackEnter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository:Report an issueSelect a topic or type what you need help withCancelSend×BibTeX RecordClick anywhere on the box above to highlight complete recordDone

--------------------------------------------------

